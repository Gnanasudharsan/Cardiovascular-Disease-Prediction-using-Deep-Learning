{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiovascular Disease Prediction - Data Exploration\n",
    "\n",
    "This notebook provides comprehensive data exploration and analysis for the cardiovascular disease prediction project.\n",
    "\n",
    "**Research Paper**: \"Transforming Healthcare With Deep Learning: Cardiovascular Disease Prediction\"  \n",
    "**Authors**: V Sasikala, J. Arunarasi, S. Surya, N. Shivaanivarsha, Guru Raghavendra S, Gnanasudharsan A\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine the cardiovascular disease dataset\n",
    "2. Perform exploratory data analysis (EDA)\n",
    "3. Identify data quality issues\n",
    "4. Understand feature distributions and relationships\n",
    "5. Generate insights for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "target_counts = df['cardio'].value_counts()\n",
    "target_percentage = df['cardio'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Target Distribution:\")\n",
    "for value, count, pct in zip(target_counts.index, target_counts.values, target_percentage.values):\n",
    "    label = \"Healthy\" if value == 0 else \"Heart Disease\"\n",
    "    print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "labels = ['Healthy', 'Heart Disease']\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "ax1.bar(labels, target_counts.values, color=colors)\n",
    "ax1.set_title('Target Variable Distribution')\n",
    "ax1.set_ylabel('Count')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    ax1.text(i, v + 500, f'{v:,}\\n({target_percentage.values[i]:.1f}%)', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(target_counts.values, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Target Variable Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check class balance\n",
    "balance_ratio = min(target_counts) / max(target_counts)\n",
    "print(f\"\\n‚öñÔ∏è  Class Balance Ratio: {balance_ratio:.3f}\")\n",
    "if balance_ratio < 0.5:\n",
    "    print(\"‚ö†Ô∏è  Dataset is imbalanced - consider balancing techniques\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset is reasonably balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "print(\"üìä CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorical_features = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    # Count plot\n",
    "    sns.countplot(data=df, x=feature, hue='cardio', ax=axes[i])\n",
    "    axes[i].set_title(f'{feature.capitalize()} Distribution by Heart Disease Status')\n",
    "    axes[i].legend(['Healthy', 'Heart Disease'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for container in axes[i].containers:\n",
    "        axes[i].bar_label(container, fmt='%d')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical analysis of categorical features\n",
    "print(\"\\nüìà CATEGORICAL FEATURES STATISTICS\")\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\n{feature.upper()}:\")\n",
    "    crosstab = pd.crosstab(df[feature], df['cardio'], normalize='index') * 100\n",
    "    print(crosstab.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze continuous features\n",
    "print(\"üìä CONTINUOUS FEATURES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create age in years for better interpretation\n",
    "df['age_years'] = df['age'] / 365.25\n",
    "df['bmi'] = df['weight'] / ((df['height'] / 100) ** 2)\n",
    "\n",
    "continuous_features = ['age_years', 'height', 'weight', 'bmi', 'ap_hi', 'ap_lo']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(continuous_features):\n",
    "    # Box plot\n",
    "    sns.boxplot(data=df, x='cardio', y=feature, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature.replace(\"_\", \" \").title()} by Heart Disease Status')\n",
    "    axes[i].set_xticklabels(['Healthy', 'Heart Disease'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary by target\n",
    "print(\"\\nüìà CONTINUOUS FEATURES STATISTICS BY TARGET\")\n",
    "for feature in continuous_features:\n",
    "    print(f\"\\n{feature.upper().replace('_', ' ')}:\")\n",
    "    stats = df.groupby('cardio')[feature].agg(['mean', 'std', 'median']).round(2)\n",
    "    stats.index = ['Healthy', 'Heart Disease']\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "print(\"üîó CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features most correlated with target\n",
    "target_correlations = correlation_matrix['cardio'].abs().sort_values(ascending=False)\n",
    "print(\"\\nüéØ FEATURES MOST CORRELATED WITH TARGET:\")\n",
    "for feature, corr in target_correlations.items():\n",
    "    if feature != 'cardio':\n",
    "        print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise relationships for key features\n",
    "print(\"üîç FEATURE RELATIONSHIPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select key features for pair plot\n",
    "key_features = ['age_years', 'bmi', 'ap_hi', 'ap_lo', 'cardio']\n",
    "pair_df = df[key_features].copy()\n",
    "\n",
    "# Create pair plot\n",
    "g = sns.pairplot(pair_df, hue='cardio', diag_kind='hist', height=2.5)\n",
    "g.fig.suptitle('Pairwise Relationships of Key Features', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Gender vs Age analysis\n",
    "print(\"\\nüë´ GENDER AND AGE ANALYSIS\")\n",
    "gender_age_cardio = df.groupby(['gender', pd.cut(df['age_years'], bins=5)])['cardio'].mean()\n",
    "print(gender_age_cardio.unstack().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights\n",
    "print(\"üí° DATA INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüîç KEY FINDINGS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Age insights\n",
    "age_disease_corr = df['age_years'].corr(df['cardio'])\n",
    "print(f\"1. Age strongly correlates with heart disease (r={age_disease_corr:.3f})\")\n",
    "\n",
    "# Gender insights\n",
    "gender_disease_rate = df.groupby('gender')['cardio'].mean()\n",
    "print(f\"2. Heart disease rate by gender:\")\n",
    "print(f\"   - Female (1): {gender_disease_rate[1]:.1%}\")\n",
    "print(f\"   - Male (2): {gender_disease_rate[2]:.1%}\")\n",
    "\n",
    "# Blood pressure insights\n",
    "bp_disease_corr = df[['ap_hi', 'ap_lo']].corrwith(df['cardio'])\n",
    "print(f\"3. Blood pressure correlation with heart disease:\")\n",
    "print(f\"   - Systolic: {bp_disease_corr['ap_hi']:.3f}\")\n",
    "print(f\"   - Diastolic: {bp_disease_corr['ap_lo']:.3f}\")\n",
    "\n",
    "# Lifestyle factors\n",
    "lifestyle_corr = df[['smoke', 'alco', 'active']].corrwith(df['cardio'])\n",
    "print(f\"4. Lifestyle factors correlation:\")\n",
    "for factor, corr in lifestyle_corr.items():\n",
    "    print(f\"   - {factor.capitalize()}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nüõ†Ô∏è  PREPROCESSING RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. Handle extreme values in blood pressure and BMI\")\n",
    "print(\"2. Create age groups for better model interpretation\")\n",
    "print(\"3. Engineer BMI categories (underweight, normal, overweight, obese)\")\n",
    "print(\"4. Create blood pressure categories based on medical guidelines\")\n",
    "print(\"5. Consider interaction terms between age and other risk factors\")\n",
    "print(\"6. Apply feature scaling for continuous variables\")\n",
    "\n",
    "print(\"\\nüéØ MODELING RECOMMENDATIONS:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"1. Dataset is reasonably balanced - no major class imbalance issues\")\n",
    "print(\"2. Strong correlations suggest good predictive potential\")\n",
    "print(\"3. Consider ensemble methods to capture complex relationships\")\n",
    "print(\"4. Use cross-validation due to sufficient sample size\")\n",
    "print(\"5. Feature selection may help reduce dimensionality\")\n",
    "print(\"6. Monitor for overfitting due to data quality issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"üìã COMPREHENSIVE DATA SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summary_stats = {\n",
    "    'Dataset Size': f\"{df.shape[0]:,} rows √ó {df.shape[1]} columns\",\n",
    "    'Memory Usage': f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\",\n",
    "    'Missing Values': f\"{df.isnull().sum().sum():,} ({(df.isnull().sum().sum() / df.size) * 100:.2f}%)\",\n",
    "    'Duplicate Rows': f\"{df.duplicated().sum():,} ({(df.duplicated().sum() / len(df)) * 100:.2f}%)\",\n",
    "    'Target Balance': f\"{balance_ratio:.3f} (Healthy: {target_percentage[0]:.1f}%, Disease: {target_percentage[1]:.1f}%)\",\n",
    "    'Age Range': f\"{df['age_years'].min():.1f} - {df['age_years'].max():.1f} years\",\n",
    "    'Strongest Predictor': f\"{target_correlations.index[1]} (r={target_correlations.iloc[1]:.3f})\"\n",
    "}\n",
    "\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key:.<30} {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ Data exploration completed successfully!\")\n",
    "print(\"üìù Proceed to data preprocessing based on insights above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on this exploration, the next steps in the analysis pipeline are:\n",
    "\n",
    "1. **Data Preprocessing** (`02_preprocessing_analysis.ipynb`)\n",
    "   - Handle extreme values and outliers\n",
    "   - Create engineered features (BMI categories, age groups)\n",
    "   - Apply feature scaling and normalization\n",
    "\n",
    "2. **Model Training** (`03_model_training.ipynb`)\n",
    "   - Implement BDLSTM + CatBoost ensemble\n",
    "   - Compare with baseline models\n",
    "   - Hyperparameter optimization\n",
    "\n",
    "3. **Model Evaluation** (`04_evaluation_comparison.ipynb`)\n",
    "   - Comprehensive performance analysis\n",
    "   - Clinical metrics evaluation\n",
    "   - Model comparison and selection\n",
    "\n",
    "4. **Feature Analysis** (`05_shap_analysis.ipynb`)\n",
    "   - SHAP feature importance analysis\n",
    "   - Model interpretability\n",
    "   - Clinical insights\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook provides the foundation for understanding the cardiovascular disease dataset and guides the subsequent analysis steps in the research pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
},
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/raw/cardiovascular_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"Please download the dataset from Kaggle and place it in data/raw/\")\n",
    "    print(\"Dataset URL: https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    df = pd.DataFrame({\n",
    "        'age': np.random.randint(10000, 25000, 1000),\n",
    "        'gender': np.random.choice([1, 2], 1000),\n",
    "        'height': np.random.randint(150, 200, 1000),\n",
    "        'weight': np.random.randint(50, 120, 1000),\n",
    "        'ap_hi': np.random.randint(80, 200, 1000),\n",
    "        'ap_lo': np.random.randint(50, 120, 1000),\n",
    "        'cholesterol': np.random.choice([1, 2, 3], 1000),\n",
    "        'gluc': np.random.choice([1, 2, 3], 1000),\n",
    "        'smoke': np.random.choice([0, 1], 1000),\n",
    "        'alco': np.random.choice([0, 1], 1000),\n",
    "        'active': np.random.choice([0, 1], 1000),\n",
    "        'cardio': np.random.choice([0, 1], 1000)\n",
    "    })\n",
    "    print(\"üìù Using sample data for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìã COLUMN INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"üëÄ FIRST 10 ROWS\")\n",
    "print(\"=\" * 50)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìà STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "if missing_df.empty:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=missing_df, x='Column', y='Missing Percentage')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(\"üîÑ DUPLICATE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates:,}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates / len(df)) * 100:.2f}%\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nüìã Sample duplicate rows:\")\n",
    "    display(df[df.duplicated()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data type issues and ranges\n",
    "print(\"üéØ DATA VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Age validation (should be reasonable)\n",
    "age_years = df['age'] / 365.25  # Convert days to years\n",
    "print(f\"Age range: {age_years.min():.1f} - {age_years.max():.1f} years\")\n",
    "\n",
    "# Check for impossible values\n",
    "print(\"\\n‚ö†Ô∏è  POTENTIAL DATA ISSUES:\")\n",
    "\n",
    "# Blood pressure issues\n",
    "bp_issues = (df['ap_hi'] <= df['ap_lo']).sum()\n",
    "print(f\"- Systolic <= Diastolic BP: {bp_issues:,} cases\")\n",
    "\n",
    "# Extreme values\n",
    "extreme_height = ((df['height'] < 100) | (df['height'] > 250)).sum()\n",
    "extreme_weight = ((df['weight'] < 30) | (df['weight'] > 200)).sum()\n",
    "extreme_bp_hi = ((df['ap_hi'] < 50) | (df['ap_hi'] > 300)).sum()\n",
    "extreme_bp_lo = ((df['ap_lo'] < 30) | (df['ap_lo'] > 200)).sum()\n",
    "\n",
    "print(f\"- Extreme height values: {extreme_height:,} cases\")\n",
    "print(f\"- Extreme weight values: {extreme_weight:,} cases\")\n",
    "print(f\"- Extreme systolic BP: {extreme_bp_hi:,} cases\")\n",
    "print(f\"- Extreme diastolic BP: {extreme_bp_lo:,} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null
}
