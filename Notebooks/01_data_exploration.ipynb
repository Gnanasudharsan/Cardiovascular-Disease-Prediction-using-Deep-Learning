{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiovascular Disease Prediction - Data Exploration\n",
    "\n",
    "This notebook provides comprehensive data exploration and analysis for the cardiovascular disease prediction project.\n",
    "\n",
    "**Research Paper**: \"Transforming Healthcare With Deep Learning: Cardiovascular Disease Prediction\"  \n",
    "**Authors**: V Sasikala, J. Arunarasi, S. Surya, N. Shivaanivarsha, Guru Raghavendra S, Gnanasudharsan A\n",
    "\n",
    "## Objectives\n",
    "1. Load and examine the cardiovascular disease dataset\n",
    "2. Perform exploratory data analysis (EDA)\n",
    "3. Identify data quality issues\n",
    "4. Understand feature distributions and relationships\n",
    "5. Generate insights for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/raw/cardiovascular_disease_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"Please download the dataset from Kaggle and place it in data/raw/\")\n",
    "    print(\"Dataset URL: https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    df = pd.DataFrame({\n",
    "        'age': np.random.randint(10000, 25000, 1000),\n",
    "        'gender': np.random.choice([1, 2], 1000),\n",
    "        'height': np.random.randint(150, 200, 1000),\n",
    "        'weight': np.random.randint(50, 120, 1000),\n",
    "        'ap_hi': np.random.randint(80, 200, 1000),\n",
    "        'ap_lo': np.random.randint(50, 120, 1000),\n",
    "        'cholesterol': np.random.choice([1, 2, 3], 1000),\n",
    "        'gluc': np.random.choice([1, 2, 3], 1000),\n",
    "        'smoke': np.random.choice([0, 1], 1000),\n",
    "        'alco': np.random.choice([0, 1], 1000),\n",
    "        'active': np.random.choice([0, 1], 1000),\n",
    "        'cardio': np.random.choice([0, 1], 1000)\n",
    "    })\n",
    "    print(\"üìù Using sample data for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìã COLUMN INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"üëÄ FIRST 10 ROWS\")\n",
    "print(\"=\" * 50)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìà STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "if missing_df.empty:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=missing_df, x='Column', y='Missing Percentage')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print(\"üîÑ DUPLICATE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates:,}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates / len(df)) * 100:.2f}%\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nüìã Sample duplicate rows:\")\n",
    "    display(df[df.duplicated()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data type issues and ranges\n",
    "print(\"üéØ DATA VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Age validation (should be reasonable)\n",
    "age_years = df['age'] / 365.25  # Convert days to years\n",
    "print(f\"Age range: {age_years.min():.1f} - {age_years.max():.1f} years\")\n",
    "\n",
    "# Check for impossible values\n",
    "print(\"\\n‚ö†Ô∏è  POTENTIAL DATA ISSUES:\")\n",
    "\n",
    "# Blood pressure issues\n",
    "bp_issues = (df['ap_hi'] <= df['ap_lo']).sum()\n",
    "print(f\"- Systolic <= Diastolic BP: {bp_issues:,} cases\")\n",
    "\n",
    "# Extreme values\n",
    "extreme_height = ((df['height'] < 100) | (df['height'] > 250)).sum()\n",
    "extreme_weight = ((df['weight'] < 30) | (df['weight'] > 200)).sum()\n",
    "extreme_bp_hi = ((df['ap_hi'] < 50) | (df['ap_hi'] > 300)).sum()\n",
    "extreme_bp_lo = ((df['ap_lo'] < 30) | (df['ap_lo'] > 200)).sum()\n",
    "\n",
    "print(f\"- Extreme height values: {extreme_height:,} cases\")\n",
    "print(f\"- Extreme weight values: {extreme_weight:,} cases\")\n",
    "print(f\"- Extreme systolic BP: {extreme_bp_hi:,} cases\")\n",
    "print(f\"- Extreme diastolic BP: {extreme_bp_lo:,} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null
